{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXnkXtCx0Ik4rzy72SzlIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonanD10/Tennis-Match-Prediction/blob/main/match_winner_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IKxEyj4d2KN",
        "outputId": "d2562874-99b7-4a9b-d9fc-dc0db0e09f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Tennis Project/features_processed_random.csv')"
      ],
      "metadata": {
        "id": "yRL3qUJhqUiK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall data\n",
        "X = features.drop(['A_won', 'slam_round'], axis=1)\n",
        "y = features['A_won']\n",
        "X_train = X[:int(0.8 * len(X))]\n",
        "y_train = y[:int(0.8 * len(y))]\n",
        "X_test = X[int(0.8 * len(y)):]\n",
        "y_test = y[int(0.8 * len(y)):]\n",
        "\n",
        "# Slam data\n",
        "slam_features = features[features['slam_round'] > 0]\n",
        "X_test_slam = features[int(0.8 * len(y)):]\n",
        "X_test_slam = X_test_slam[X_test_slam['slam_round'] > 0]\n",
        "y_test_slam = X_test_slam['A_won']\n",
        "X_test_slam = X_test_slam.drop(['A_won', 'slam_round'], axis=1)\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test_slam = scaler.transform(X_test_slam)"
      ],
      "metadata": {
        "id": "A7JEbN1mEWBA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing models\n",
        "\n",
        "models = [LogisticRegression(max_iter=10000), RandomForestClassifier(), SVC()]\n",
        "\n",
        "# Overall predictions\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'{model.__class__.__name__} accuracy: {accuracy}')\n",
        "\n",
        "# Slam predictions only\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test_slam)\n",
        "    accuracy = accuracy_score(y_test_slam, y_pred)\n",
        "    print(f'{model.__class__.__name__} accuracy: {accuracy}')\n",
        "\n",
        "# Slam predictions, trained only on slam data\n",
        "X_train_slam = slam_features[:int(0.8 * len(slam_features))]\n",
        "y_train_slam = X_train_slam['A_won']\n",
        "X_train_slam = X_train_slam.drop(['A_won', 'slam_round'], axis=1)\n",
        "\n",
        "for model in models:\n",
        "    model.fit(X_train_slam, y_train_slam)\n",
        "    y_pred = model.predict(X_test_slam)\n",
        "    accuracy = accuracy_score(y_test_slam, y_pred)\n",
        "    print(f'{model.__class__.__name__} accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "CLBUwRSBIc_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy per slam round\n",
        "\n",
        "def slam_accuracy(features, round, model):\n",
        "\n",
        "    X = features.drop(['A_won', 'slam_round'], axis=1)\n",
        "    y = features['A_won']\n",
        "    X_train = X[:int(0.8 * len(X))]\n",
        "    y_train = y[:int(0.8 * len(y))]\n",
        "\n",
        "    test = features[int(0.8 * len(y)):]\n",
        "    test_slams = test[test['slam_round'] == round]\n",
        "    X_test = test_slams.drop(['A_won', 'slam_round'], axis=1)\n",
        "    y_test = test_slams['A_won']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "for i in range(1, 8):\n",
        "    accuracy = slam_accuracy(features, i, model)\n",
        "    print(f'Accuracy for slam round {i}: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sYVdd6yAwdR",
        "outputId": "a53c7bc3-dd54-484c-c1cf-52fb408e6e35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for slam round 1: 0.8402041617589321\n",
            "Accuracy for slam round 2: 0.8056206088992974\n",
            "Accuracy for slam round 3: 0.7667682926829268\n",
            "Accuracy for slam round 4: 0.7530487804878049\n",
            "Accuracy for slam round 5: 0.75\n",
            "Accuracy for slam round 6: 0.8048780487804879\n",
            "Accuracy for slam round 7: 0.7560975609756098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slam upsets (lower ranked wins)\n",
        "\n",
        "slam_features_upset_A = slam_features[(slam_features['A_rank'] > slam_features['B_rank']) & (slam_features['A_won'] == 1)]\n",
        "slam_features_upset_B = slam_features[(slam_features['A_rank'] < slam_features['B_rank']) & (slam_features['A_won'] == 0)]\n",
        "slam_features_upset = pd.concat([slam_features_upset_A, slam_features_upset_B])\n",
        "y_test_slam_upset = slam_features_upset['A_won']\n",
        "slam_features_upset = slam_features_upset.drop(['A_won', 'slam_round'], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "slam_features_upset = scaler.transform(slam_features_upset)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(slam_features_upset)\n",
        "accuracy = accuracy_score(y_test_slam_upset, y_pred)\n",
        "print(f'Upset prediction accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88iPCYktEBEp",
        "outputId": "32cffadb-bb9e-49e8-9612-fa964136bffc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upset prediction accuracy: 0.5914718019257221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kn6MZeDHF0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model coeffs -- graphs and explanations\n",
        "# Compare classification models (gridsearchCV) & explain why better and worse\n",
        "#"
      ],
      "metadata": {
        "id": "x0OxDCX1rgXA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning Model"
      ],
      "metadata": {
        "id": "F2-8nC4-gcEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, in_features=21, h1=24, h2=24, out_features=2):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = Model()\n",
        "\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(list(y_test))"
      ],
      "metadata": {
        "id": "ZctOBQ1-h_r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 1000\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(X_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  if loss < 5:\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "  if i % 50 == 0:\n",
        "    print(f'Epoch: {i} and loss: {loss}')\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWEMQYniiLsR",
        "outputId": "5971df7d-3603-471f-f29d-7d2e65f56453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 and loss: 0.41927477717399597\n",
            "Epoch: 50 and loss: 0.4226013123989105\n",
            "Epoch: 100 and loss: 0.42005351185798645\n",
            "Epoch: 150 and loss: 0.41951823234558105\n",
            "Epoch: 200 and loss: 0.4192602336406708\n",
            "Epoch: 250 and loss: 0.4191246032714844\n",
            "Epoch: 300 and loss: 0.41901645064353943\n",
            "Epoch: 350 and loss: 0.41892099380493164\n",
            "Epoch: 400 and loss: 0.41883841156959534\n",
            "Epoch: 450 and loss: 0.4187612235546112\n",
            "Epoch: 500 and loss: 0.41867920756340027\n",
            "Epoch: 550 and loss: 0.41860705614089966\n",
            "Epoch: 600 and loss: 0.4185396432876587\n",
            "Epoch: 650 and loss: 0.4184684157371521\n",
            "Epoch: 700 and loss: 0.41840142011642456\n",
            "Epoch: 750 and loss: 0.4183393716812134\n",
            "Epoch: 800 and loss: 0.41828030347824097\n",
            "Epoch: 850 and loss: 0.4182570278644562\n",
            "Epoch: 900 and loss: 0.41818875074386597\n",
            "Epoch: 950 and loss: 0.41809308528900146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_eval = model.forward(X_test)\n",
        "  loss = criterion(y_eval, y_test)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy_score(y_test, torch.argmax(y_eval, dim=1))}')\n",
        "print(sum(torch.argmax(y_eval, dim=1) != y_test))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FildsAVKjwFA",
        "outputId": "2c6e50d5-3200-4d6f-8081-a4ad418398ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.40476226806640625\n",
            "Accuracy: 0.8095705040203962\n",
            "tensor(971)\n",
            "5099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy per slam round"
      ],
      "metadata": {
        "id": "J6J-7A4SdAKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(losses)), losses)\n",
        "plt.ylabel(\"loss/error\")\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "68RhymNLjJwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting outcome based only on ranking\n",
        "correct = 0\n",
        "for i in range(len(features)):\n",
        "    if features.loc[i, 'A_rank'] < features.loc[i, 'B_rank'] and features.loc[i, 'A_won'] == 1:\n",
        "        correct += 1\n",
        "    elif features.loc[i, 'A_rank'] > features.loc[i, 'B_rank'] and features.loc[i, 'A_won'] == 0:\n",
        "        correct += 1\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "print('Rank accuracy: ', correct/len(features))\n",
        "\n",
        "# Predicting outcome based only on Elo\n",
        "correct = 0\n",
        "for i in range(len(features)):\n",
        "    if features.loc[i, 'A_elo'] > features.loc[i, 'B_elo'] and features.loc[i, 'A_won'] == 1:\n",
        "        correct += 1\n",
        "    elif features.loc[i, 'A_elo'] < features.loc[i, 'B_elo'] and features.loc[i, 'A_won'] == 0:\n",
        "        correct += 1\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "print('Elo accuracy: ', correct/len(features))\n",
        "\n",
        "# Predicting outcome based only on 12 month form\n",
        "correct = 0\n",
        "for i in range(len(features)):\n",
        "    if features.loc[i, 'A_12month_form'] > features.loc[i, 'B_12month_form'] and features.loc[i, 'A_won'] == 1:\n",
        "        correct += 1\n",
        "    elif features.loc[i, 'A_12month_form'] < features.loc[i, 'B_12month_form'] and features.loc[i, 'A_won'] == 0:\n",
        "        correct += 1\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "print('12-month form accuracy: ', correct/len(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmHE2NpEON4q",
        "outputId": "f3e4e923-16ff-4641-d683-6a0d67950b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank accuracy:  0.6595385753496636\n",
            "Elo accuracy:  0.6650834145700676\n",
            "12-month form accuracy:  0.718582125152967\n"
          ]
        }
      ]
    }
  ]
}